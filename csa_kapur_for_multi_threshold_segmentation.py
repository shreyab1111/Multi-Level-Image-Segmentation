# -*- coding: utf-8 -*-
"""CSA_Kapur for multi-threshold segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ogFH8rT_sGADFQ-8sO8M1j1Lm2qSSoLg
"""

#CODE BY: SHREYA BISWAS

!pip install sewar
import cv2
import numpy as np
import random
from PIL import Image
import matplotlib.pyplot as plt
from math import log10, sqrt 
import skimage 
from skimage import filters
import math 
from skimage import io
from google.colab.patches import cv2_imshow

from itertools import combinations

def kapur_entropy(h,thresholds,nthrs):
  #COUNTING PIXELS
  cnt = 0
  for i in range(0, len(h)):
    if h[i]>0:
           cnt += h[i]
  
  #FINDING PROBABILITY OF AN INDIVIDUAL PIXEL
  prob=[]
  for i in range (len(h)):
    h[i]=h[i]/cnt
    prob.append(h[i])
  
  '''KAPUR'S ENTROPY CALCULATION'''
  ###sum of intensity values for each segment created by threshold MARKED IN PURPLE
  SUM=[]
  SUM.append(sum(h[0:thresholds[0]]))

  for i in range(len(thresholds)-1):
    #print(i)   ###th1 to th2, th2 to th3, thn-1 to thn
    #SUM.append(sum(h[thresholds[i]:thresholds[i+1]]))
    if(sum(h[thresholds[i]:thresholds[i+1]]) == 0):
      SUM.append(2.07)
    else:
      SUM.append(sum(h[thresholds[i]:thresholds[i+1]]))

  SUM.append(sum(h[thresholds[nthrs-1]:255]))   ##thn to 256

  #### CALCULATING WO AS MARKED IN BLUE FOR EACH SEGMENT CREATED BY THE THRESHOLDS
  w0=prob[:]
  for k in range(len(thresholds)):
    if(k==0):
      for i in range(0,thresholds[k]):
        #print(i)
        w0[i]=w0[i]/SUM[k]
    if((k+1)==len(thresholds)):
      for i in range(thresholds[k-1],255):
        w0[i]=w0[i]/SUM[k]
    else:
      for i in range(thresholds[k-1],thresholds[k]):
        w0[i]=w0[i]/SUM[k]
  ### CALCULATING W1 AS MARKED IN RED FOR EACH SEGMENT CREATED BY THE THRESHOLDS
  w1=prob[:]
  for k in range(len(thresholds)):
    if(k==0):
      for i in range(0,thresholds[k]):
        if w1[i]==0:
          w1[i]=w1[i]
        else:
          w1[i]=math.log(abs(w1[i]/SUM[k]))
    if(k==len(thresholds)-1):
      for i in range(thresholds[k-1],255):
        if w1[i]==0:
          w1[i]=w1[i]
        else:
          w1[i]=math.log(abs(w1[i]/SUM[k]))
    else:
      for i in range(thresholds[k-1],thresholds[k]):
        if w1[i]==0:
          w1[i]=w1[i]
        else:
          w1[i]=math.log(abs(w1[i]/SUM[k]))

  ###MULTIPLYING W0 AND W1 AS IN THE FORMULAE
  mul=[]
  for i in range(len(w0)):
    mul.append(w0[i]*w1[i])

  ### GETTING THE SUM OF THE ABOVE MULTIPLIED QUANTITY FOR EACH SEGMENT
  kapur_entropy=[]
  for i in range(len(thresholds)-1):
    kapur_entropy.append(-(sum(mul[thresholds[i]:thresholds[i+1]])))

  #OBJECTIVE FUNCTION 
  J=sum(kapur_entropy)
  return (J)

def fitness(xn, n ,pd, greyscale_img):	#function for fitness calculation
    hist, _ = np.histogram(greyscale_img,bins=range(256), density=True)
    '''for i in range(len(hist)):
      if(hist[i] == 0):
        hist[i] = 0.001'''
    fitness = np.zeros(n)
    #fitness.append(0)
    for i in range(n):
        #print(kapur_entropy(hist, xn[i],pd))
        fitness[i] = int(kapur_entropy(hist, xn[i],pd))
    return fitness

def distance(a,b,dim):
    o = np.zeros(dim)
    for i in range(0,len(a)):
        o[i] = abs(a[i] - b[i])
    return o

def Levy(d):
    beta=3/2
    sigma=(math.gamma(1+beta)*math.sin(math.pi*beta/2)/(math.gamma((1+beta)/2)*beta*2**((beta-1)/2)))**(1/beta)
    u=np.random.randn(d)*sigma
    v=np.random.randn(d)
    step=u/abs(v)**(1/beta)
    o=0.01*step
    return o        

img_list=[1]

def init(n, pd, l, u): #init the matrix problem
  x = []
  l=l+30
  u=u-30
  for i in range (n):
    x.append([])
    for j in range (pd):
      x[i].append(int(l + random.uniform(0,1)*(u-l)))
  
  return x

#Crow Search Algorithm

import time,os

threshno = [1,2,3,4,5,6,7]
img_list = '/content/drive/MyDrive/Dataset/Standard_images_Copy/'
for img_name in os.listdir(img_list):
  for nthrs in threshno:
    start = time.time()
    print("Image Name " + str(img_name))
    sr=img_list+img_name
    greyscale_img = cv2.imread(sr,0)
    
    dim=nthrs
    
    ### Parameters

    pd = dim		#Problem dimension (number of decision variables)
    n = 5		#Flock (population) size
    ap = 0.1	#Awareness probability
    fl = 2		#Flight length (fl)
    l = 0	#Lower
    u = 255		#Uper
    
    x = init(n, pd, l, u)
    xn = x.copy()
    #print(xn)
    ft = np.array(fitness(xn, n, pd, greyscale_img))

    mem = x.copy()			#Memory initialization
    fit_mem = ft.copy()		#Fitness of memory positions
    tmax = 50			#Max numuber of iterations (itermax)
    ffit = np.array([])	# Best fit of each iteration

    ### Parameter end 
    for t in range(tmax):
      #print("Iteration = " + str(t))
      num = np.array([random.randint(1, n-1) for _ in range(n)]) # Generation of random candidate crows for following (chasing)
      xnew = np.zeros((n,pd))
      for i in range (n):
        for j in range (pd):
            xnew[i][j] = abs(int(x[i][j]+fl*((random.random())*(mem[num[i]][j]-x[i][j]))))
	  
      #print('\n')
      #print((xnew).astype(int).tolist())
      xn = xnew.copy().astype(int).tolist()
      for i in range(len(xn)):
        xn[i].sort()
      #print(xn)
      try:
        ft = np.array(fitness(xn, n, pd,greyscale_img)) #Function for fitness evaluation of new solutions
      except:
        ft = ft
    
      #Update position and memory#
      for i in range(n):
        if(xnew[i].all() > l and xnew[i].all() < u):
          x[i] = xnew[i].copy()		#Update position
          if(ft[i] < fit_mem[i]):
            mem[i] = xnew[i].copy()	#Update memory
            fit_mem[i] = ft[i]
      
      ffit = np.append(ffit, np.amin(fit_mem)) 	#Best found value until iteration t
      ngbest, = np.where(np.isclose(fit_mem, min(fit_mem)))

    ffit = np.append(ffit, np.amin(fit_mem)) 	#Best found value until iteration t
    ngbest, = np.where(np.isclose(fit_mem, min(fit_mem)))
    mem[ngbest[0]].sort()
    print(mem[ngbest[0]])

    end = time.time()
    print(end-start)
    print('end\n\n\n')